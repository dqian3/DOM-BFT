{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6cd730f-fe32-49df-8f06-c92d71f26238",
   "metadata": {},
   "source": [
    "## Protocol Analysis\n",
    "\n",
    "It would probably be good to make these actual python libraries. Oh well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbe798-a911-4532-bf83-8993548159b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First extract logs with \"PERF\" from the client/receiver logs\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "filename=\"final/c24_kv_512_nice/dombft_fast_sr900.out\"\n",
    "\n",
    "if not Path(filename).exists():\n",
    "    !cat ../logs/replica*.log ../logs/client*.log | grep PERF >{filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1ffec-95cf-4c13-bd78-f212d168e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic log parsing\n",
    "\n",
    "import re\n",
    "import datetime \n",
    "\n",
    "def parse_time(line):\n",
    "    match = re.search(f\"([0-9]*:[0-9]*:[0-9]*.[0-9]*)\", line)\n",
    "    time_str = match.group(1);\n",
    "    return datetime.datetime.strptime(time_str, \"%H:%M:%S.%f\")\n",
    "\n",
    "def parse_tags(line):\n",
    "    tags = {}\n",
    "    line = line.split(\"PERF \")[1]\n",
    "    for token in line.split():\n",
    "        [tag, value] = token.split(\"=\")\n",
    "        tags[tag] = value\n",
    "        try:\n",
    "            tags[tag] = int(value)\n",
    "        except ValueError as verr:\n",
    "            pass\n",
    "            \n",
    "    return tags\n",
    "        \n",
    "def parse_line(line):\n",
    "    time = parse_time(line)\n",
    "    tags = parse_tags(line)\n",
    "\n",
    "    tags[\"time\"] = time\n",
    "    return tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8b1d34-d4d7-465b-b369-f40124bb9592",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_events = []\n",
    "\n",
    "with open(filename) as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            all_events.append(parse_line(line))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "all_events = sorted(all_events, key=lambda x: x['time'])\n",
    "all_commits = list(filter(lambda x: x[\"event\"] == \"commit\", all_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e92f00f-d1af-441a-9155-41fce7569066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at each client commit, make sure there are no two clients ops on the same seq\n",
    "from collections import Counter\n",
    "\n",
    "# counts = Counter(c[\"seq\"] for c in all_commits if c[\"path\"] != \"missed\")\n",
    "# for seq in counts:\n",
    "#     if counts[seq] > 1:\n",
    "#         print(f\"Sequence {seq} has different commits!\")\n",
    "#         print(list(\n",
    "#             f\"c_id={x['client_id']} c_seq={x['client_seq']} path={x['path']} round={x['round']}\" \n",
    "#            for x in filter(lambda x: x[\"seq\"] == seq, all_commits)\n",
    "#         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a633cf06-9ef9-4c3e-8e66-6bca84842ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all client operations are committed\n",
    "clients = set(x['client_id'] for x in all_commits)\n",
    "\n",
    "# for c_id in clients:\n",
    "#     c_commits = filter(lambda x: x[\"client_id\"] == c_id, all_commits)\n",
    "#     seq = sorted(c[\"client_seq\"] for c in c_commits)\n",
    "\n",
    "#     for x, y in zip(seq, seq[1:]):\n",
    "#         if (y-x) > 1:\n",
    "#             print(f\"Client {c_id} missed commits between {x + 1}-{y - 1}\")\n",
    "        \n",
    "#         if x == y:\n",
    "#             print(f\"Client {c_id} repeated commits {x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679cd5ae-20e2-48d2-92db-baca91d6252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = all_events[0]['time'] + datetime.timedelta(seconds=45)\n",
    "end_time = all_events[-1]['time'] - datetime.timedelta(seconds=45)\n",
    "\n",
    "events = list(filter(lambda x: x['time'] > start_time and x['time'] < end_time, all_events))\n",
    "commits = list(filter(lambda x: x[\"event\"] == \"commit\", events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a9b1c2-e56e-429f-9b98-3aea7006f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get general stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "runtime = (commits[-1][\"time\"] - start_time).total_seconds()\n",
    "print(f\"Runtime: {runtime:.3f} s\")\n",
    "print(f\"Total Throughput: {len(commits) / runtime:.2f} req/s\")\n",
    "\n",
    "latencies = np.array([c['latency'] for c in commits])\n",
    "print(f\"Num commits: {len(commits)}\")\n",
    "print(f\"Average latency: {np.mean(latencies):.0f} us\")\n",
    "print(f\"p95 latency: {np.percentile(latencies, 95):.0f} us\")\n",
    "print(f\"p99 latency: {np.percentile(latencies, 99):.0f} us\")\n",
    "\n",
    "fast = list(filter(lambda x: x[\"path\"] == \"fast\", commits))\n",
    "normal = list(filter(lambda x: x[\"path\"] == \"normal\", commits))\n",
    "slow = list(filter(lambda x: x[\"path\"] == \"slow\", commits))\n",
    "missed = list(filter(lambda x: x[\"path\"] == \"missed\", commits))\n",
    "\n",
    "print(\"Fast path:\")\n",
    "print(f\"\\tNum commits: {len(fast)}\")\n",
    "if len(fast) > 0:\n",
    "    print(f\"\\tAverage latency: {sum(c['latency'] for c in fast) / len(fast):.0f} us\")\n",
    "\n",
    "\n",
    "print(\"Normal path:\")\n",
    "print(f\"\\tNum commits: {len(normal)}\")\n",
    "if len(normal) > 0:\n",
    "    print(f\"\\tAverage latency: {sum(c['latency'] for c in normal) / len(normal):.0f} us\")\n",
    "\n",
    "print(\"Slow path:\")\n",
    "print(f\"\\tNum commits: {len(slow)}\")\n",
    "if len(slow) > 0:\n",
    "    print(f\"\\tAverage latency: {sum(c['latency'] for c in slow) / len(slow):.0f} us\")\n",
    "\n",
    "print(\"Missed path:\")\n",
    "print(f\"\\tNum commits: {len(missed)}\")\n",
    "if len(missed) > 0:\n",
    "    print(f\"\\tAverage latency: {sum(c['latency'] for c in missed) / len(missed):.0f} us\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d6a91-1379-4561-9112-7bbeba73abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the throughput over periods of 100ms every 10ms  \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "w_size = 10 #s\n",
    "resolution = 0.1 #s\n",
    "\n",
    "end = (commits[-1][\"time\"] - start_time).total_seconds()\n",
    "\n",
    "for c in commits:\n",
    "     c[\"t\"] = (c[\"time\"] - start_time).total_seconds()\n",
    "\n",
    "w_start = 0\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "commit_counts = []\n",
    "commit_paths = []\n",
    "\n",
    "while w_start + w_size < end:\n",
    "    while (commits[i][\"t\"] < w_start):\n",
    "        i += 1\n",
    "    while (commits[j][\"t\"] <= w_start + w_size):\n",
    "        j += 1\n",
    "\n",
    "    commit_counts.append(j - i)\n",
    "\n",
    "    if (j > i):\n",
    "        path_counts = Counter(c[\"path\"] for c in commits[i:j])\n",
    "        commit_paths.append(path_counts.most_common(1)[0][0])\n",
    "    else:\n",
    "        commit_paths.append(\"slow\")\n",
    "    \n",
    "    w_start += resolution\n",
    "\n",
    "\n",
    "times = np.arange(0, end - w_size, resolution)\n",
    "throughput = np.array(commit_counts) / w_size\n",
    "\n",
    "def pathToColor(path):\n",
    "    if path == \"fast\": return 'g'\n",
    "    elif path == \"normal\": return 'b'\n",
    "    elif path == \"slow\": return 'r'\n",
    "    else: return 'grey'\n",
    "\n",
    "colors=[ pathToColor(path) for path in commit_paths ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b05e6b-acbc-40dd-b119-c6903b94e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first fallback start time for each instance\n",
    "\n",
    "fallback_starts = list(filter(lambda x: x[\"event\"] == \"repair_start\" and x[\"replica_id\"] == 0, events))\n",
    "\n",
    "fallback_starts_t = [\n",
    "    (x[\"time\"] - start_time).total_seconds()\n",
    "    for x in fallback_starts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6cb9e-0aae-4259-9316-824d2c873ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot throughput over time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(times, throughput, label='Throughput', linestyle=\"--\")\n",
    "plt.vlines(fallback_starts_t, min(throughput), max(throughput), color='m', linestyle='dotted', label='fallback start', alpha=0.5)\n",
    "\n",
    "plt.title('Throughput Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(f'Throughput (Avg. over {w_size}s)')\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim(0, None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02159ae0-1482-4558-aaa1-c8c157b0b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same graph, but with indications of which type of commit was done\n",
    "plt.vlines(fallback_starts_t, min(throughput), max(throughput), color='m', linestyle='dotted', label='fallback start', alpha=0.5)\n",
    "plt.scatter(times, throughput, label='Throughput', alpha=1, c=colors)\n",
    "\n",
    "\n",
    "plt.title('Throughput Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(f'Throughput (Avg. over {w_size}s)')\n",
    "plt.legend()\n",
    "plt.ylim(0, None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c153a-cd0d-42f9-bf3f-50c605a9f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [x for x in commits if x[\"client_id\"] == 3]\n",
    "\n",
    "start_times = [x[\"time\"].timestamp() - x[\"latency\"] / 10**6 for x in cs]\n",
    "min_t = min(start_times)\n",
    "\n",
    "starts = [t - min_t for t in start_times] \n",
    "\n",
    "data = list(zip(starts, cs))\n",
    "data = sorted(data, key=lambda t: t[0])\n",
    "\n",
    "latencies = [(t, x[\"latency\"] / 1000) for t, x in data]\n",
    "t, latencies = zip(*latencies)\n",
    "\n",
    "plt.ylim(top=1000)\n",
    "\n",
    "plt.plot(t, latencies)\n",
    "plt.vlines(fallback_starts_t, min(throughput), max(throughput), color='m', linestyle='dotted', label='fallback start', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395200bb-d5d8-4f62-901f-30e9adfb0ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min((x for x in latencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25753ec9-77c9-4f3a-9f79-645928cae5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data\n",
    "latencies_sorted = np.sort(latencies)\n",
    "\n",
    "# Calculate the CDF values\n",
    "cdf = np.arange(1, len(latencies_sorted) + 1) / len(latencies_sorted)\n",
    "\n",
    "# Plot\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(latencies_sorted, cdf)\n",
    "plt.title('Latency CDF')\n",
    "plt.xlabel('Latency (ms)')\n",
    "plt.ylabel('CDF')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d14091-5a56-4ef5-8a93-77aa0eae4d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
